{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP 6 Membership Attack - solution guidelines (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "cba0d3f1-4510-472f-de6b-3530bdc5487d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#project_path = 'include pathe to where your notebook is located on the drive'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "927d92e9-dd14-4884-b267-73714001b4b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10('../data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10('../data', train=True,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "29e99986-8394-4cb9-fcea-916805bdf3e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " frog horse   dog truck\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwD3QHRwcHKYI3APdwcHBYYrg/wNh3rDnj38I/gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "a1983bd4-48bf-43c8-b66a-3eb0f26380ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "test_size = len(testset)\n",
        "#loader_size = len(trainloader)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "#print(loader_size)\n",
        "\n",
        "print(total_size, test_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx = indices[split3:total_size]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "outputId": "a30c8e3a-cb05-4028-8c98-d5e57849889e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_batch_size = 128 # pick your own\n",
        "test_batch_size = 64\n",
        "\n",
        "#train_batch_size = 128 # maybe only need one\n",
        "#test_batch_size = 64\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx)\n",
        "shadow_out_loader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx)\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx)\n",
        "\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_loader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, sampler=target_out_sampler)\n",
        "\n",
        "print(len(shadow_train_loader))\n",
        "print(len(shadow_out_loader))\n",
        "print(len(target_train_loader))\n",
        "print(len(target_out_loader))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98\n",
            "196\n",
            "98\n",
            "196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(8192, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "9a182563-4bc0-4af3-b39d-f9351e4ccd7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "epochs = 20\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "target_model = CNN()\n",
        "target_model.to(device)\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "optimizer = optim.Adam(target_model.parameters(), lr = .001)# try Adam VS SGD\n",
        "\n",
        "# let the magic begin\n",
        "for epoch in range(epochs):  \n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for i, data in enumerate(target_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # make a prediction: forward prop\n",
        "        #print(inputs.shape)\n",
        "        outputs = target_model(inputs)\n",
        "                       \n",
        "        # calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "                       \n",
        "        # backwards propogation\n",
        "        loss.backward()       \n",
        "        \n",
        "       \n",
        "\n",
        "        # calculate gradients\n",
        "        optimizer.step()\n",
        "        # updaate weights in backprop\n",
        "                       \n",
        "                       \n",
        "        running_loss += loss.data\n",
        "        # print statistics\n",
        "        \n",
        "    ##train_accuracy = calculate_accuracy(trainloader)\n",
        "    ##test_accuracy = calculate_accuracy(testloader)\n",
        "\n",
        "    running_loss_normal = running_loss / len(target_train_loader)\n",
        "    print(\"Running Loss: %f , Normalized: %f\" % (running_loss, running_loss_normal))\n",
        "\n",
        "    #print(\"Iteration: {0} | Loss: {1} | Training accuracy: {2}% | Test accuracy: {3}%\".format(epoch+1, running_loss, train_accuracy, test_accuracy))\n",
        "        \n",
        "        \n",
        "\n",
        "print('Finished Training the Target model...')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Loss: 185.574234 , Normalized: 1.893615\n",
            "Running Loss: 151.831146 , Normalized: 1.549297\n",
            "Running Loss: 138.282974 , Normalized: 1.411051\n",
            "Running Loss: 126.807106 , Normalized: 1.293950\n",
            "Running Loss: 119.700676 , Normalized: 1.221435\n",
            "Running Loss: 109.588593 , Normalized: 1.118251\n",
            "Running Loss: 104.968285 , Normalized: 1.071105\n",
            "Running Loss: 99.515739 , Normalized: 1.015467\n",
            "Running Loss: 95.066246 , Normalized: 0.970064\n",
            "Running Loss: 93.664368 , Normalized: 0.955759\n",
            "Running Loss: 87.049095 , Normalized: 0.888256\n",
            "Running Loss: 84.368797 , Normalized: 0.860906\n",
            "Running Loss: 82.469635 , Normalized: 0.841527\n",
            "Running Loss: 79.453140 , Normalized: 0.810746\n",
            "Running Loss: 77.422150 , Normalized: 0.790022\n",
            "Running Loss: 75.387833 , Normalized: 0.769264\n",
            "Running Loss: 73.833023 , Normalized: 0.753398\n",
            "Running Loss: 71.191078 , Normalized: 0.726440\n",
            "Running Loss: 69.621811 , Normalized: 0.710427\n",
            "Running Loss: 66.680855 , Normalized: 0.680417\n",
            "Finished Training the Target model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCKORSk8oamd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(target_model.state_dict(), 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZW6cKOKobQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#state_dict = torch.load('checkpoint.pth')\n",
        "#target_model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "71c372b0-b2b4-4736-9f5f-466a9462e65e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in target_out_loader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = target_model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "##print(total)\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 70 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "c68179a7-8765-43e9-f341-902a6016b507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = CNN()\n",
        "shadow_model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(shadow_model.parameters(), lr = .001)\n",
        "\n",
        "# let the magic begin\n",
        "for epoch in range(epochs):  \n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for i, data in enumerate(shadow_train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # make a prediction: forward prop\n",
        "        #print(inputs.shape)\n",
        "        outputs = shadow_model(inputs)\n",
        "                       \n",
        "        # calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "                       \n",
        "        # backwards propogation\n",
        "        loss.backward()       \n",
        "        \n",
        "       \n",
        "\n",
        "        # calculate gradients\n",
        "        optimizer.step()\n",
        "        # updaate weights in backprop\n",
        "                       \n",
        "                       \n",
        "        running_loss += loss.data\n",
        "        # print statistics\n",
        "        \n",
        "    ##train_accuracy = calculate_accuracy(trainloader)\n",
        "    ##test_accuracy = calculate_accuracy(testloader)\n",
        "    running_loss_normal = running_loss / len(target_train_loader)\n",
        "    print(\"Running Loss: %f , Normalized: %f\" % (running_loss, running_loss_normal))\n",
        "\n",
        "    #print(\"Iteration: {0} | Loss: {1} | Training accuracy: {2}% | Test accuracy: {3}%\".format(epoch+1, running_loss, train_accuracy, test_accuracy))\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Loss: 183.840271 , Normalized: 1.875921\n",
            "Running Loss: 148.404770 , Normalized: 1.514334\n",
            "Running Loss: 134.870834 , Normalized: 1.376233\n",
            "Running Loss: 124.832291 , Normalized: 1.273799\n",
            "Running Loss: 116.009613 , Normalized: 1.183771\n",
            "Running Loss: 108.826576 , Normalized: 1.110475\n",
            "Running Loss: 100.450844 , Normalized: 1.025009\n",
            "Running Loss: 95.483322 , Normalized: 0.974320\n",
            "Running Loss: 90.872208 , Normalized: 0.927267\n",
            "Running Loss: 87.658676 , Normalized: 0.894476\n",
            "Running Loss: 84.434616 , Normalized: 0.861578\n",
            "Running Loss: 80.753304 , Normalized: 0.824013\n",
            "Running Loss: 76.059708 , Normalized: 0.776119\n",
            "Running Loss: 74.161499 , Normalized: 0.756750\n",
            "Running Loss: 72.088226 , Normalized: 0.735594\n",
            "Running Loss: 69.815300 , Normalized: 0.712401\n",
            "Running Loss: 66.955086 , Normalized: 0.683215\n",
            "Running Loss: 66.367058 , Normalized: 0.677215\n",
            "Running Loss: 64.200333 , Normalized: 0.655105\n",
            "Running Loss: 60.304512 , Normalized: 0.615352\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e3gk1Qao4rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(shadow_model.state_dict(), 'shadow_checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fmP19JdI4wF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#state_dict = torch.load('shadow_checkpoint.pth')\n",
        "#target_model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "outputId": "83bafd69-e1fe-4c74-c3ed-ff0de6cb375e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# freeze the Shadow model \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 1] and zip them together\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "#attack_data_set = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in shadow_out_loader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = shadow_model(inputs)\n",
        "        \n",
        "        #attack_data_set.append((outputs, torch.tensor([1.0], requires_grad=True)))\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        \n",
        "    print('Accuracy of the shadow network on the shadow_train_loader: %d %%' % (100 * correct / total))\n",
        " \n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the shadow network on the shadow_train_loader: 71 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQxXd8J9djuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shadow_model.eval()\n",
        "\n",
        "for param in shadow_model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "attack_data = []\n",
        "\n",
        "for inputs, labels in shadow_train_loader:\n",
        "  inputs, labels = inputs.to(device), labels.to(device)\n",
        "  predictions = shadow_model(inputs)\n",
        "  \n",
        "  for i in range(predictions.shape[0]):\n",
        "    attack_data.append((predictions[i], 1))\n",
        "  \n",
        "for inputs, labels in shadow_out_loader:\n",
        "  inputs, labels = inputs.to(device), labels.to(device)\n",
        "  predictions = shadow_model(inputs)\n",
        "  \n",
        "  for i in range(predictions.shape[0]):\n",
        "    attack_data.append((predictions[i], 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tyg15oVJUwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(len(attack_data_set))\n",
        "attack_data_loader = torch.utils.data.DataLoader(attack_data, batch_size=4, shuffle=True)\n",
        "#print(len(attack_data_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHZg-j0_MfzN",
        "colab_type": "code",
        "outputId": "129b6459-4e4e-4225-b2fe-1fe86b285689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(shadow_train_loader))\n",
        "print(len(shadow_out_loader))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98\n",
            "196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ymKnj7QpdDG",
        "colab_type": "code",
        "outputId": "70c0c843-0a2c-4f6f-e354-2051bfb20aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "\n",
        "\n",
        "\n",
        "epochs = 20;\n",
        "# Build a feed-forward network\n",
        "attack_model = nn.Sequential(nn.Linear(10, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "\n",
        "attack_model.to(device)\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(attack_model.parameters(), lr=.001)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "\n",
        "    running_loss = 0.0\n",
        "    count = 0\n",
        "    for i, data in enumerate(attack_data_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        count +=1\n",
        "        #print(\"Data loader count:  %d\" % count)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        # make a prediction: forward prop\n",
        "        #print(inputs.shape)\n",
        "        outputs = attack_model(inputs)\n",
        "                       \n",
        "        # calculate loss\n",
        "        ##print(outputs)\n",
        "        ##print(labels)\n",
        "        loss = criterion(outputs, labels)\n",
        "                       \n",
        "        # backwards propogation\n",
        "        loss.backward()       \n",
        "        \n",
        "       \n",
        "\n",
        "        # calculate gradients\n",
        "        optimizer.step()\n",
        "        # updaate weights in backprop\n",
        "                       \n",
        "                       \n",
        "        running_loss += loss.data\n",
        "        # print statistics\n",
        "        \n",
        "    ##train_accuracy = calculate_accuracy(trainloader)\n",
        "    ##test_accuracy = calculate_accuracy(testloader)\n",
        "    running_loss_normal = running_loss / len(target_train_loader)\n",
        "    print(\"Running Loss: %f , Normalized: %f\" % (running_loss, running_loss_normal))\n",
        "\n",
        "    #print(\"Iteration: {0} | Loss: {1} | Training accuracy: {2}% | Test accuracy: {3}%\".format(epoch+1, running_loss, train_accuracy, test_accuracy))\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "print('Finished Training the Attack Model')\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Loss: 4304.198242 , Normalized: 43.920391\n",
            "Running Loss: 4229.552734 , Normalized: 43.158699\n",
            "Running Loss: 4203.489746 , Normalized: 42.892750\n",
            "Running Loss: 4182.977051 , Normalized: 42.683437\n",
            "Running Loss: 4166.133789 , Normalized: 42.511570\n",
            "Running Loss: 4155.324219 , Normalized: 42.401268\n",
            "Running Loss: 4139.922852 , Normalized: 42.244110\n",
            "Running Loss: 4134.703613 , Normalized: 42.190853\n",
            "Running Loss: 4122.627441 , Normalized: 42.067627\n",
            "Running Loss: 4118.304688 , Normalized: 42.023518\n",
            "Running Loss: 4100.903320 , Normalized: 41.845951\n",
            "Running Loss: 4095.807373 , Normalized: 41.793953\n",
            "Running Loss: 4089.010254 , Normalized: 41.724594\n",
            "Running Loss: 4086.851807 , Normalized: 41.702568\n",
            "Running Loss: 4077.893799 , Normalized: 41.611160\n",
            "Running Loss: 4067.718262 , Normalized: 41.507328\n",
            "Running Loss: 4061.197266 , Normalized: 41.440788\n",
            "Running Loss: 4059.256592 , Normalized: 41.420986\n",
            "Running Loss: 4049.099365 , Normalized: 41.317341\n",
            "Running Loss: 4049.599609 , Normalized: 41.322445\n",
            "Finished Training the Attack Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mn5PgLWo9za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(attack_model.state_dict(), 'attack_checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ07s_NyIdKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#state_dict = torch.load('attack_checkpoint.pth')\n",
        "#target_model.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "952248ba-4e08-45b8-efbc-287c28e34141"
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "# and then input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in target_train_loader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = target_model(inputs)\n",
        "        \n",
        "        ##attack_data_loader.append((outputs, 1))\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        \n",
        "    print('Accuracy of the attack network on the target_train_loader: %d %%' % (100 * correct / total))\n",
        "    out_correct = 0\n",
        "    out_total = 0\n",
        "        \n",
        "    for data in target_out_loader:\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = target_model(inputs)\n",
        "        \n",
        "        ##attack_data_loader.append((outputs, 0))\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        out_total += labels.size(0)\n",
        "        out_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the attack network on the target_out_loader: %d %%' % (100 * out_correct / out_total))\n",
        "    \n",
        "    correct += out_correct\n",
        "    total += out_total\n",
        "    print('Total accuracy of the attack network: %d %%' % (100 * out_correct / out_total))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the attack network on the target_train_loader: 74 %\n",
            "Accuracy of the attack network on the target_out_loader: 70 %\n",
            "Total accuracy of the attack network: 70 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2w1eRMjMVw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "# and then input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "\n",
        "\n",
        "# Run attack agains the target model\n",
        "actual_value = []\n",
        "pred_value = []\n",
        "\n",
        "attack_model.eval()\n",
        "\n",
        "for param in attack_model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for inputs, labels in target_train_loader:\n",
        "  inputs, labels = inputs.to(device), labels.to(device)\n",
        "  \n",
        "  # Get probability output of target model\n",
        "  output = target_model(inputs)\n",
        "  \n",
        "  # Run through attack model\n",
        "  pred = attack_model(output)\n",
        "  \n",
        "  # Pull out top class\n",
        "  top_p, top_class = pred.topk(1, dim=1)\n",
        "  \n",
        "  for i in range(top_class.shape[0]):\n",
        "    pred_value.append(top_class[0].item())\n",
        "    actual_value.append(1)\n",
        "    \n",
        "for inputs, labels in target_out_loader:\n",
        "  inputs, labels = inputs.to(device), labels.to(device)\n",
        "  \n",
        "  # Get probability output of target model\n",
        "  output = target_model(inputs)\n",
        "  \n",
        "  # Run through attack model\n",
        "  pred = attack_model(output)\n",
        "  \n",
        "  # Pull out top class\n",
        "  top_p, top_class = pred.topk(1, dim=1)\n",
        "  \n",
        "  for i in range(top_class.shape[0]):\n",
        "    pred_value.append(top_class[0].item())\n",
        "    actual_value.append(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNXD6hf_MafB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for i in range(len(actual_value)):\n",
        " # print(\"Actual: {}   Prediction: {}\".format(actual_value[i], pred_value[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCeG4rQBMVtu",
        "colab_type": "code",
        "outputId": "5e4e7d1e-fd49-454b-a128-8d81ad3b735d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Calculate recall and precision\n",
        "# precison = true positive / true positive + false positive\n",
        "true_pos = 0\n",
        "false_neg = 0\n",
        "\n",
        "total_positive = sum(pred_value)\n",
        "for i in range(len(actual_value)):\n",
        "  if (pred_value[i] == 1) and (actual_value[i] == 1):\n",
        "    true_pos += 1\n",
        "  elif (pred_value[i] == 0 and actual_value[i] == 1):\n",
        "    false_neg += 1\n",
        "    \n",
        "print('True positive: {} Total Positive: {} Precision: {}'.format(true_pos, total_positive, true_pos / total_positive))\n",
        "print('Recall: {}', true_pos / (true_pos + false_neg))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True positive: 11220 Total Positive: 21800 Precision: 0.5146788990825688\n",
            "Recall: {} 0.8976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}